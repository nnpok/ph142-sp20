---
title: "Homework 9"
author: "Your name and student ID"
date: "Today's date"
output:
  pdf_document: default
---

* Due date: April 21st 10:00pm (make sure to provide enough time for Gradescope
submission to be uploaded if you include large image files).
```{r, warning=F, message=F, echo=F}
library(dplyr)
library(ggplot2)
library(readr)
library(ggrepel)
library(broom)
library(tidyr)
```

* Late penalty: 50% late penalty if submitted within 24 hours of due date, no 
marks for assignments submitted thereafter.
* This assignment is marked out of 32 points. Marks are indicated for each 
question. 
* Remember: autograder is meant as sanity check ONLY. It will not tell you if you have the correct answer. It will tell you if you are in the ball park of the answer so *CHECK YOUR WORK*
* Submission process: Follow the submission instructions on the final page. Make sure you do not remove any `\newpage` tags or rename this file, as this will break the submission.

```{r setup, include = FALSE}
# Don't change these lines, just run them!
source("setup/hw09.RAGS.R")
```

Helpful hints:

-  Every function you need to use was taught during lecture! So you may need to 
revisit the lecture code to help you along by opening the relevant files on Datahub. 
Alternatively, you may wish to view the code in the condensed PDFs posted 
on the course website. Good luck!

- Knit your file early and often to minimize knitting errors! If you copy and 
paste code for the slides, you are bound to get an error that is hard to 
diagnose. Typing out the code is the way to smooth knitting! We recommend 
knitting your file each time after you write a few sentences/add a new code 
chunk, so you can detect the source of knitting errors more easily. This will 
save you and the GSIs from frustration! **You must knit right before submitting**

- If your code runs off the page of the knitted PDF then you will LOSE POINTS! To
avoid this, have a look at your knitted PDF and ensure all the code fits in the 
file. When it doesn't, go back to your .Rmd file and add spaces (new lines) using
the return or enter key so that the code runs onto the next line.

Round your answers to 3 decimal places in general.
--------------------------------------------------------------------------------
\newpage

### Section 1: Abstract interpretation [5 points]
Read the following abstract and answer the questions that follow. 
J Asthma. 2018 Oct 11:1-12. doi: 10.1080/02770903.2018.1508471. [Epub ahead of print]
Impact of scenario based training on asthma first aid knowledge and skills in school staff: an open label, three-arm, parallel-group repeated measures study.
Luckie K1, Saini B1, Soo YYB1,2, Kritikos V1,3, Charles Collins JB1, Jane Moles R1.

OBJECTIVE:
To test the hypothesis that scenario-based skills training is more effective than knowledge training alone in improving the asthma first aid (AFA) skills of school personnel. Education developed specifically for non-primary caregivers such as school staff is vital to minimize the risk of mortality associated with asthma.

METHODS:
Schools were allocated to one of three arms to compare AFA knowledge and AFA skills. Arm 1 underwent conventional asthma training, arm 2 underwent scenario-based training and arm 3 had a combination of the two. Conventional asthma training involved a didactic oral presentation. The scenario-based skills training required the participant to describe and demonstrate how they would manage a child having a severe exacerbation of asthma using equipment provided. Follow-up occurred at 3 weeks post baseline and again between 3-7 months after the first training/education visit.

RESULTS:
Nineteen primary schools (204 participants) were recruited. One-way ANOVA and Bonferroni Post-Hoc Tests showed there was a significant difference in AFA skills scores between the study arms who underwent scenario-based training; arms 2 and 3 (91.5% and 91.1%) and arm 1 who underwent conventional asthma training (77.3%) (p<0.001). AFA knowledge improved significantly in all study arms with no differences between study arms. Improvements seen in both AFA knowledge and AFA skills were maintained over time.

CONCLUSIONS:
Scenario-based training was superior to conventional didactic asthma training for AFA skills acquisition and overall competency in the administration of AFA and should be included in future asthma training programs.

\newpage

1. [1 point]	Two methods of hypothesis testing (types of tests) are mentioned in the abstract.  What is the null hypothesis for each of these tests (please list in the order they are mentioned in the abstract?

$H_{0}$:  [YOUR ANSWER HERE] - one sentence only 


$H_{0}$:  [YOUR ANSWER HERE] - one sentence only 


\newpage

2. [1 point] There are two outcomes of interest in this study.  For which **outcome** would you conclude that there is a significant difference between the training groups.  

[YOUR ANSWER HERE]


\newpage

3. [1 point] If you were a school administrator why might you choose the arm 3 training?

[YOUR ANSWER HERE]

\newpage

4. [1 point] List one question you might want to ask about the methods, sample or results that would help you interpret the findings of this study?

[YOUR ANSWER HERE]


\newpage

5. [1 point]  What is another test that could have been considered for these study data?

[YOUR ANSWER HERE]


\newpage

### Section 2: ANOVA and Tukey's HSD [6 points]
For this question we will use the data from the NHANES survey
`
```{r read, echo=FALSE}
# Read CSV into R
nhanes <- read_csv("nhanes.csv")
head(nhanes)

nhanes <- na.omit(nhanes) #remove rows with missing values
```

\newpage

6. [1 point] Generate the mean and standard deviations in a dataframe for blood lipid level "lbdldl" by Blood pressure group "bpcat". Use dplyr functions.

```{r}
p6 <- "Your code here"
p6


check_problem6()
```

\newpage

7. [1 point] Create a boxplot that helps you to visualize these data.

```{r}
p7 <- "Your plot here"
p7


check_problem7()
```

\newpage

8. [2 points]  Conduct an ANOVA with Tukey's HSD for these data. Assign your model to the variable `tukey`.

```{r, warning = F}
tukey <- "Your code here"
p8 <- tidy(tukey) #keep this line


check_problem8()

```

\newpage

9. [1 point]  What are the null and alternative hypotheses for this test?

[YOUR ANSWER HERE]


\newpage

10. [1 point]  What do you conclude from your analysis?

[YOUR ANSWER HERE]


\newpage

### Section 3: Non-parametric [3 points]
You are testing the change in test scores following an intensive tutoring session.  
You have the following data from a small group of students each student is tested before and after the tutoring session.  
Each row represents one student.  

|Time 1   |Time 2|
|---------|------|
|65       |77    |
|87       |100   |
|77       |75    |
|90       |89    |
|70       |80    |
|84       |81    |
|92       |91    |
|83       |96    |
|85       |84    |
|91       |89    |
|68       |88    |
|72       |100   |
|81       |81    |
|---------|------|

```{r}
#this code makes a dataframe of the table you see above
test_scores <- tribble(
  ~time1, ~time2,
  65, 77,
  87, 100,
  77, 75,
  90, 89,
  70, 80,
  84, 81,
  92, 91,
  83, 96,
  85, 84,
  91, 89,
  68, 88,
  72, 100,
  81, 81)

```


11. [2 point] Calculate the appropriate non-paramentric test for these data by hand. Attach an image to show your work. Make sure to place the image in the `src` directory. Uncomment the line by deleting the pound sign. Report the p-value> Keep it as a decimal and round to 4 places.

```{r}
#knitr::include_graphics("src/path-to-file")
p11 <- "YOUR P-VALUE HERE"
p11


check_problem11()
```


\newpage

12. [1 point] Check your work using [insert your test].test() function in R. Keep your answer as a decimal rounded to 4 decimals. Report your p-value and save it to the variable p12.

```{r, warning=FALSE}
p12 <- "Your p-value here"
p12

check_problem12()
```

\newpage


### Section 4: Voting during the 1992 election [21 points]

In the spirit of the upcoming 2020 presidential election, I thought it would be 
interesting to consider some historical data on voting patterns across US counties.

This code loads in the data frame `counties`:

```{r}
load("A10_counties.sav")
```

These data are from the 1992 election and looks at the percent of votes cast 
(for each county) for the `democrat` (Bill Clinton), `republican` (George Bush),
and independent presidential nominees (Ross `Perot`). 

Ideally, if you were interested in voting patterns, you might look at the 
relationship between individual characteristics and whether each individual 
voted Democrat or Republican. However, data like that is often hard to come by.
The `counties` data provide data on 3141 counties. Use `View()` to examine these
data briefly and read the labels corresponding to the variables. Note that Alaska
is not included and that two other counties with populations = 0 have also been 
excluded.

As discussed in class we have the entire population (not just a sample), so 
strictly speaking we don't need to perform statistical inference. However, we
might pretend this is a sample so that we can apply the techniques of inference 
and gain competence creating and interpeting a linear model.

\newpage

13. [2 points] Looking only at California, plot the relationship between 
the % of votes cast for the Democratic candidate (`democrat`) 
and the population density of the county (`pop.density`). Since we will only be using the counties from California, go ahead and subset the full `counties` dataset to only include observations from the state of CA. 

```{r}
counties_CA <- "SUBSET DATA HERE"

p13 <- "YOUR PLOT HERE"
p13


check_problem13()
```

\newpage

14. [1 point] The above plot you made does not look very good. 
The distribution of population density is skewed right, 
with a few counties having much higher densities than the majority of counties.
To see which counties these are, we will use `geom_text_repel` from the 
library `ggrepel` (loaded at the top of this assignment). 
The template for using this function is: 
`geom_text_repel(aes(label = your_labelling_var))`. 
You will want to set the labeling variable to be the variable in the dataset
containing the county names.

```{r}
p14 <- "YOUR CODE HERE"
p14


check_problem14()
```

The current issue with these data is that San Francisco 
(as you can now hopefully point out) 
has a much higher population density than other counties, 
and that generally there is a large right skew in the distribution 
of the population density variable. 

If we tried and fit a linear model to these data, it would not fit well-- because
the relationship between population density and the response variable is not 
linear. However, this is the perfect situation to try transforming the x variable.

\newpage

15. [2 points] Try adding a log-transformed version of population density to the data frame and remake your plot using this new variable. Call this new variable `log_pop_density`. Keep the population labels. Also add a smoothed fitted line:

```{r}
# uncomment the line below by deleting the pound sign
# counties_CA <- "Add new variable here"

p15 <- "YOUR PLOT HERE"
p15


check_problem15()
```

\newpage

16. [4 points] Describe the relationship between the (logged) population density 
and the response variable in terms of the shape, direction, strength, and outliers.
These are concepts from Chapter 3. Calculate the correlation (round to 4 decimals) to comment on one of these aspects.

```{r}
p16 <- "CALCULATE THE CORRELATION HERE"
p16

check_problem16()
```


[YOUR ANSWER HERE]



\newpage

17. [4 points] Run a linear model regression of the % votes cast for the democratic
candidate as a function of the population density. Make sure you get the order
of variables right in the `lm()` function! Use the `tidy()` function to show the 
slope and intercept estimates. Interpret the relationship between the logged population 
density and the response variable. (You can `View()` the data frame to make sure
you are getting your units right by checking the descriptions in the labels for 
each variable). Use another function from `broom` show the r-squared. Report and interpret this value for the model.

```{r}
lm_CA <- "YOUR MODEL HERE"

r.squared <- "Report r-squared here. Leave as decimal and round to 2 places"


check_problem17()
```

[YOUR ANSWER HERE]


\newpage

18. [4 points] Using the code learned in class, that was also shown in Lab 9, make the four plots to examine the assumptions.

```{r}

plot1 <- "Code for scatterplot here"
plot1

plot2 <- "Code for QQ plot here"
plot2

plot3 <- "Code for Fitted vs. Residuals plot here"
plot3

plot4 <- "Code for Amount explained plot here"
plot4


check_problem18()
```

19. [4 points] Comment on each of the plots and conclude about which 
assumptions appear violated vs. not violated. Don't forget to comment on the 
one assumption that cannot be investigated using plots.

[YOUR ANSWER HERE]


\newpage

### Check your score

Click on the middle icon on the top right of this code chunk (with the downwards gray arrow and green bar) to run all your code in order. Then, run this chunk to check your score.
```{r check-total-score}
# Just run this chunk.
total_score()
```

\newpage

### Submission

For assignments in this class, you'll be submitting using the **Terminal** tab in the pane below. In order for the submission to work properly, make sure that:

1. Any image files you add that are needed to knit the file are in the `src` folder and file paths are specified accordingly. 
2. You **have not changed the file name** of the assignment.
3. The file is saved (the file name in the tab should be **black**, not red with an asterisk).
4. The file knits properly.

Once you have checked these items, you can proceed to submit your assignment.

1. Click on the **Terminal** tab in the pane below.
2. Copy-paste the following line of code into the terminal and press enter.

cd; cd ph142-sp20/hw/hw09; python3 turn_in.py

3. Follow the prompts to enter your Gradescope username and password. When entering your password, you won't see anything come up on the screen--don't worry! This is just for security purposes--just keep typing and hit enter.
4. If the submission is successful, you should see "Submission successful!" appear as output.
5. If the submission fails, try to diagnose the issue using the error messages--if you have problems, post on Piazza. 

The late policy will be strictly enforced, **no matter the reason**, including submission issues, so be sure to submit early enough to have time to diagnose issues if problems arise.


